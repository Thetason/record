import { NextRequest, NextResponse } from 'next/server';
export const runtime = 'nodejs';
export const dynamic = 'force-dynamic';
import { getServerSession } from 'next-auth';
import { authOptions } from '@/lib/auth';
import { prisma } from '@/lib/prisma';
import crypto from 'crypto';
import sharp from 'sharp';
import { LRUCache } from 'lru-cache';
import cleanKoreanReview, { stripCommonNoiseLines as stripNoiseLocal, normalizeWhitespacePunct as normPunct } from '@/lib/text-clean';
import { improveSpacingViaService } from '@/lib/spacing-service';
import { rateLimit, getIP, rateLimitResponse, apiLimits } from '@/lib/rate-limit';
const vision = require('@google-cloud/vision');

// Google Vision API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
let visionClient: any = null;
const cache = new LRUCache<string, any>({ max: 500, ttl: 1000 * 60 * 60 * 24 * 7 });
const enableTesseractFallback = process.env.ENABLE_TESSERACT_FALLBACK === 'true';
const visionTimeoutMs = Number(process.env.OCR_VISION_TIMEOUT_MS || 18000);
const limiter = rateLimit({ interval: 60 * 1000, uniqueTokenPerInterval: 500 });

function withTimeout<T>(promise: Promise<T>, ms: number, label: string): Promise<T> {
  if (!ms || Number.isNaN(ms) || ms <= 0) {
    return promise;
  }
  return new Promise<T>((resolve, reject) => {
    const timer = setTimeout(() => {
      reject(new Error(`TIMEOUT_${label}_${ms}`));
    }, ms);

    promise
      .then(value => {
        clearTimeout(timer);
        resolve(value);
      })
      .catch(error => {
        clearTimeout(timer);
        reject(error);
      });
  });
}

// ì´ˆê¸°í™” í•¨ìˆ˜
async function initializeVisionClient() {
  if (visionClient) return visionClient;
  
  try {
    console.log('Vision API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹œì‘...');
    console.log('GOOGLE_APPLICATION_CREDENTIALS:', process.env.GOOGLE_APPLICATION_CREDENTIALS);
    
    // Base64 ì¸ì½”ë”©ëœ í‚¤ê°€ ìˆëŠ” ê²½ìš° (Vercel í”„ë¡œë•ì…˜)
    if (process.env.GOOGLE_VISION_API_KEY) {
      console.log('Base64 í‚¤ ì‚¬ìš©');
      const credentials = JSON.parse(
        Buffer.from(process.env.GOOGLE_VISION_API_KEY, 'base64').toString()
      );
      visionClient = new vision.ImageAnnotatorClient({
        credentials,
        projectId: credentials.project_id,
      });
    } 
    // ë¡œì»¬ JSON íŒŒì¼ ê²½ë¡œê°€ ìˆëŠ” ê²½ìš° (ê°œë°œ í™˜ê²½)
    else if (process.env.GOOGLE_APPLICATION_CREDENTIALS) {
      console.log('ë¡œì»¬ í‚¤ íŒŒì¼ ì‚¬ìš©:', process.env.GOOGLE_APPLICATION_CREDENTIALS);
      visionClient = new vision.ImageAnnotatorClient({
        keyFilename: process.env.GOOGLE_APPLICATION_CREDENTIALS
      });
    }
    
    if (visionClient) {
      console.log('âœ… Vision API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ');
    } else {
      console.log('âŒ Vision API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨');
    }
  } catch (error) {
    console.error('âŒ Google Vision API ì´ˆê¸°í™” ì—ëŸ¬:', error);
  }
  
  return visionClient;
}

export async function POST(req: NextRequest) {
  let lastUploadedBuffer: Buffer | null = null;
  try {
    // Feature flag: allow disabling OCR and always return mock
    const ocrEnabled = process.env.ENABLE_OCR !== 'false';
    console.log('ğŸ“¸ OCR API í˜¸ì¶œë¨');

    if (!ocrEnabled) {
      return NextResponse.json(
        {
          success: false,
          error: 'OCR ê¸°ëŠ¥ì´ í˜„ì¬ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.'
        },
        { status: 503 }
      );
    }

    // Rate limiting (per IP)
    const clientIp = getIP(req) || 'unknown';
    try {
      await limiter.check(req, apiLimits.ocr, `ocr_${clientIp}`);
    } catch {
      return rateLimitResponse(60);
    }

    // ì¸ì¦ í™•ì¸
    const session = await getServerSession(authOptions);
    if (!session?.user?.id) {
      return NextResponse.json(
        {
          success: false,
          error: 'ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.'
        },
        { status: 401 }
      );
    }

    // ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ
    const user = await prisma.user.findUnique({
      where: { id: session.user.id },
      select: { id: true, plan: true, reviewLimit: true }
    });

    if (!user) {
      return NextResponse.json(
        {
          success: false,
          error: 'ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
        },
        { status: 404 }
      );
    }

    // ìš”ì²­ ë°ì´í„° íŒŒì‹±
    let formData;
    try {
      formData = await req.formData();
    } catch (parseError) {
      console.error('FormData íŒŒì‹± ì—ëŸ¬:', parseError);
      return NextResponse.json(
        { 
          success: false,
          error: 'ì˜ëª»ëœ ìš”ì²­ í˜•ì‹ì…ë‹ˆë‹¤.' 
        },
        { status: 400 }
      );
    }
    
    const image = formData.get('image') as File;
    
    if (!image) {
      return NextResponse.json(
        { 
          success: false,
          error: 'ì´ë¯¸ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.' 
        },
        { status: 400 }
      );
    }

    // ì´ë¯¸ì§€ í¬ê¸° ì²´í¬ (10MB ì œí•œ)
    if (image.size > 10 * 1024 * 1024) {
      return NextResponse.json(
        { 
          success: false,
          error: 'ì´ë¯¸ì§€ í¬ê¸°ëŠ” 10MB ì´í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.' 
        },
        { status: 400 }
      );
    }

    // Build cache key from image hash
    const bufRaw = Buffer.from(await image.arrayBuffer());
    lastUploadedBuffer = bufRaw;
    const hash = crypto.createHash('sha256').update(bufRaw).digest('hex');
    const cached = cache.get(hash);
    if (cached) {
      return NextResponse.json({ success: true, data: cached, cache: true });
    }

    // Preprocess image to improve OCR
    let processed = bufRaw;
    try {
      const img = sharp(bufRaw).resize({ width: 1600, withoutEnlargement: true }).grayscale().normalize();
      // optional threshold to reduce UI noise; avoid over-binarization for photos
      processed = await img.toBuffer();
    } catch {}

    // Vision API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    const client = ocrEnabled ? await initializeVisionClient() : null;
    
    // Vision APIê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš° Mock ë°ì´í„° ë°˜í™˜
    if (!client) {
      console.log('Google Vision APIê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ. Mock ë°ì´í„° ë°˜í™˜');
      
      // ê°œë°œìš© Mock ë°ì´í„°
      const mockData = {
        text: 'â­â­â­â­â­ 5.0\n\nì •ë§ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì„œë¹„ìŠ¤ì˜€ìŠµë‹ˆë‹¤!\nì„ ìƒë‹˜ì´ ë„ˆë¬´ ì¹œì ˆí•˜ì‹œê³  ì „ë¬¸ì ì´ì„¸ìš”.\në‹¤ìŒì—ë„ ê¼­ ë‹¤ì‹œ ì°¾ê³  ì‹¶ìŠµë‹ˆë‹¤.\n\n2024ë…„ 12ì›” 15ì¼\në„¤ì´ë²„ ë¦¬ë·°',
        platform: 'naver',
        rating: 5,
        date: '2024-12-15',
        confidence: 0.95
      };
      
      return NextResponse.json({
        success: true,
        data: mockData,
        mock: true,
        message: 'OCR APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.'
      });
    }

    // ì´ë¯¸ì§€ë¥¼ Bufferë¡œ ë³€í™˜
    const buffer = processed;

    // Google Vision API í˜¸ì¶œ
    console.log(`ğŸ” Vision API í˜¸ì¶œ ì‹œì‘... (timeout: ${visionTimeoutMs}ms)`);
    // Prefer documentTextDetection to get structured blocks/paragraphs/words
    const [result] = await withTimeout(
      client.documentTextDetection({
        image: { content: buffer.toString('base64') },
        imageContext: { languageHints: ['ko', 'en'] }
      }),
      visionTimeoutMs,
      'VISION'
    );

    // Try Google's assembled text first
    const full = result.fullTextAnnotation?.text?.trim();
    // Fallback to annotations array
    const detections = result.textAnnotations;
    
    if (!full && (!detections || detections.length === 0)) {
      // Try Tesseract fallback before giving up (load lazily to avoid worker bundling issues)
      if (enableTesseractFallback) {
        try {
          const { default: Tesseract } = await import('tesseract.js');
          const tess = await Tesseract.recognize(buffer, 'kor+eng');
          const tText = (tess?.data?.text || '').trim();
          if (tText) {
            const cleanedT = cleanKoreanReview(stripNoiseLocal(refineSpacing(tText)), { maskPII: true, strong: true });
            const tExtract = analyzeReviewText(cleanedT);
            const payload = {
              ...tExtract,
              text: cleanedT,
              rawText: tText,
              normalizedText: cleanedT,
              confidence: 0.7,
              engine: 'tesseract',
              postprocess: 'local'
            }
            cache.set(hash, payload);
            return NextResponse.json({ success: true, data: payload });
          }
        } catch (e) {
          console.warn('Tesseract fallback failed or unavailable:', e);
        }
      } else {
        console.warn('Tesseract fallback ë¹„í™œì„±í™”ë¨ (ENABLE_TESSERACT_FALLBACK !== "true")');
      }
      return NextResponse.json({ success: false, error: 'í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.' }, { status: 422 });
    }
    
    // Rebuild text in reading order when Google's assembled text is noisy
    const rebuilt = rebuildReadingOrder(result);
    const rawFullText = (rebuilt || full || detections?.[0]?.description || '').trim();
    // Local cleaning
    const normalization = await normalizeForAnalysis(rawFullText);
    let baseForCleaner = normalization.baseText;
    // External cleaner (optional)
    let cleaned = baseForCleaner;
    let externalApplied = false;
    const svc = process.env.TEXT_CLEAN_SERVICE_URL;
    if (svc) {
      try {
        const ctrl = new AbortController();
        const t = setTimeout(() => ctrl.abort(), 2000);
        const resp = await fetch(svc, { method: 'POST', body: JSON.stringify({ text: baseForCleaner }), headers: { 'Content-Type': 'application/json' }, signal: ctrl.signal });
        clearTimeout(t);
        if (resp.ok) {
          const j: any = await resp.json();
          const external = (j.cleaned || j.text);
          if (external && typeof external === 'string') {
            cleaned = external;
            externalApplied = true;
          }
        }
      } catch {}
    }

    // Final safety normalization
    cleaned = cleanKoreanReview(cleaned, { maskPII: true, strong: true });
    
    // í…ìŠ¤íŠ¸ ë¶„ì„ ë° ë°ì´í„° ì¶”ì¶œ(Spacing ì„œë¹„ìŠ¤ ì ìš© ê²°ê³¼ ê¸°ì¤€)
    const extractedData = analyzeReviewText(baseForCleaner);

    // OCR ì‚¬ìš© ê¸°ë¡ ì €ì¥ (ì„ì‹œ ë¹„í™œì„±í™”)
    /*
    await prisma.activityLog.create({
      data: {
        userId: user.id,
        action: 'OCR_SCAN',
        category: 'review',
        details: {
          platform: extractedData.platform,
          rating: extractedData.rating,
          textLength: fullText.length
        }
      }
    });
    */

    const postSteps: string[] = [];
    if (normalization.spacingApplied) postSteps.push('spacing-service');
    if (externalApplied) postSteps.push('external');
    postSteps.push('local');

    const payload = {
      ...extractedData,
      text: cleaned,
      rawText: rawFullText,
      normalizedText: cleaned,
      confidence: (Array.isArray(detections) && detections[0] && (detections[0] as any).confidence) ? (detections[0] as any).confidence : 0.9,
      engine: 'google',
      postprocess: postSteps.join('+'),
      intermediateText: {
        denoised: normalization.denoised,
        base: baseForCleaner
      }
    }
    cache.set(hash, payload);
    return NextResponse.json({ success: true, data: payload });

  } catch (error) {
    console.error('OCR ì²˜ë¦¬ ì—ëŸ¬:', error);
    if (enableTesseractFallback && error instanceof Error && error.message?.startsWith('TIMEOUT_VISION')) {
      console.error('Vision API timeout ë°œìƒ, Tesseract fallback ì‹œë„');
    }
    if (enableTesseractFallback && lastUploadedBuffer) {
      try {
        const { default: Tesseract } = await import('tesseract.js');
        const tess = await Tesseract.recognize(lastUploadedBuffer, 'kor+eng');
        const tText = (tess?.data?.text || '').trim();
        if (tText) {
          const normalization = await normalizeForAnalysis(tText);
          let baseForCleaner = normalization.baseText;
          let cleanedT = baseForCleaner;
          let externalApplied = false;

          if (process.env.TEXT_CLEAN_SERVICE_URL) {
            try {
              const ctrl = new AbortController();
              const t = setTimeout(() => ctrl.abort(), 2000);
              const resp = await fetch(process.env.TEXT_CLEAN_SERVICE_URL, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ text: baseForCleaner }),
                signal: ctrl.signal
              });
              clearTimeout(t);
              if (resp.ok) {
                const j: any = await resp.json();
                const external = (j.cleaned || j.text);
                if (external && typeof external === 'string') {
                  cleanedT = external;
                  externalApplied = true;
                }
              }
            } catch {}
          }

          cleanedT = cleanKoreanReview(cleanedT, { maskPII: true, strong: true });
          const tExtract = analyzeReviewText(baseForCleaner);
          const postSteps = [] as string[];
          if (normalization.spacingApplied) postSteps.push('spacing-service');
          if (externalApplied) postSteps.push('external');
          postSteps.push('local');
          const payload = {
            ...tExtract,
            text: cleanedT,
            rawText: tText,
            normalizedText: cleanedT,
            confidence: 0.7,
            engine: 'tesseract',
            postprocess: postSteps.join('+'),
            intermediateText: {
              denoised: normalization.denoised,
              base: baseForCleaner
            }
          }
          return NextResponse.json({ success: true, data: payload });
        }
      } catch (e) {
        console.warn('Tesseract final fallback failed or unavailable:', e);
      }
    }
    return NextResponse.json({ success: false, error: 'OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.' }, { status: 504 });
  }
}

// í…ìŠ¤íŠ¸ì—ì„œ ë¦¬ë·° ì •ë³´ ì¶”ì¶œ
function analyzeReviewText(text: string) {
  const cleaned = normalizeText(text);
  // í”Œë«í¼ ê°ì§€
  let platform = 'unknown';
  if (
    cleaned.includes('ë„¤ì´ë²„') || cleaned.includes('NAVER') ||
    /ë¦¬ë·°\s*[\d,]+.*ì‚¬ì§„\s*[\d,]+/.test(cleaned) ||
    /^íŒ”ë¡œìš°$/m.test(cleaned)
  ) {
    platform = 'naver';
  } else if (text.includes('ì¹´ì¹´ì˜¤') || text.includes('kakao')) {
    platform = 'kakao';
  } else if (text.includes('ì¸ìŠ¤íƒ€ê·¸ë¨') || text.includes('Instagram')) {
    platform = 'instagram';
  } else if (text.includes('êµ¬ê¸€') || text.includes('Google')) {
    platform = 'google';
  }

  // í‰ì  ì¶”ì¶œ (ë³„ì  ë˜ëŠ” ìˆ«ì)
  let rating = 5;
  const starMatch = cleaned.match(/â­+/);
  if (starMatch) {
    rating = starMatch[0].length;
  } else {
    const ratingMatch = cleaned.match(/(\d+(?:\.\d+)?)\s*(?:ì |\/\s*5)/);
    if (ratingMatch) {
      rating = Math.min(5, Math.max(1, parseFloat(ratingMatch[1])));
    }
  }

  // ë‚ ì§œ ì¶”ì¶œ
  let date = new Date().toISOString().split('T')[0];
  const datePatterns = [
    /(\d{4})[ë…„.-](\d{1,2})[ì›”.-](\d{1,2})/,
    /(\d{1,2})[ì›”.-](\d{1,2})[ì¼]/,
    /(\d{4})\.(\d{1,2})\.(\d{1,2})/,
    /(\d{1,2})\.(\d{1,2})(?:\.(?:ì›”|\w+))?/,
    /(\d{1,2})\s*ì¼\s*ì „/, // 3ì¼ ì „
    /(ì–´ì œ|ê·¸ì œ)/
  ];
  
  for (const pattern of datePatterns) {
    const dateMatch = cleaned.match(pattern);
    if (dateMatch) {
      if (pattern.source.includes('ì¼\\s*ì „')) {
        const days = parseInt(dateMatch[1], 10) || 0;
        const d = new Date();
        d.setDate(d.getDate() - days);
        date = d.toISOString().split('T')[0];
      } else if (dateMatch[1] === 'ì–´ì œ' || dateMatch[1] === 'ê·¸ì œ') {
        const delta = dateMatch[1] === 'ì–´ì œ' ? 1 : 2;
        const d = new Date();
        d.setDate(d.getDate() - delta);
        date = d.toISOString().split('T')[0];
      } else {
        const y = dateMatch[1];
        const year = y && y.length === 4 ? y : String(new Date().getFullYear());
        const month = (dateMatch[2] || dateMatch[1]).toString();
        const day = (dateMatch[3] || dateMatch[2]).toString();
        date = `${month.length === 1 && year === String(new Date().getFullYear()) && !dateMatch[3] ? year : year}-${month.padStart(2,'0')}-${day.padStart(2,'0')}`;
      }
      break;
    }
  }

  // ì‘ì„±ìëª… ì¶”ì¶œ (ì„ íƒì )
  let author = '';
  const authorPatterns = [
    /ì‘ì„±ì\s*[:ï¼š]\s*([^\n]+)/,
    /ë‹‰ë„¤ì„\s*[:ï¼š]\s*([^\n]+)/,
    /([ê°€-í£A-Za-z0-9*]{2,15})\s*ë‹˜/
  ];
  
  for (const pattern of authorPatterns) {
    const authorMatch = cleaned.match(pattern);
    if (authorMatch) {
      author = authorMatch[1].trim();
      break;
    }
  }

  // ë„¤ì´ë²„ ì „ìš© íŒŒì„œ: ìƒë‹¨ ë©”íƒ€/íŒ”ë¡œìš°/ì ‘ê¸°/í•˜ë‹¨ íƒœê·¸ ì œê±°, ë³¸ë¬¸ë§Œ ì¶”ì¶œ
  let body = cleaned;
  let business = '';
  if (platform === 'naver') {
    const n = parseNaver(cleaned);
    author = n.author || author;
    date = n.date || date;
    body = n.body || cleaned;
    business = n.business || '';
  } else if (platform === 'kakao') {
    const k = parseKakao(cleaned);
    author = k.author || author;
    date = k.date || date;
    body = k.body || cleaned;
  } else {
    body = parseGeneric(cleaned);
  }

  return {
    platform,
    rating,
    date,
    author,
    business,
    reviewText: body
  };
}

function normalizeText(s: string): string {
  return s
    .replace(/\r\n?/g, '\n')
    .replace(/[\t\f\v]+/g, ' ')
    .replace(/ +/g, ' ')
    .replace(/[\u200B-\u200D\uFEFF]/g, '')
    .trim();
}

// ê³µí†µ UI ë…¸ì´ì¦ˆ ë¼ì¸ ì œê±°(í”Œë«í¼ ê³µí†µ ìš”ì†Œë“¤)
function stripCommonNoiseLines(text: string): string {
  const rawLines = text.split('\n').map(l => l.trim());
  const uiWords = [
    'íŒ”ë¡œìš°','íŒ”ë¡œì‰','í”„ë¡œí•„','ë²ˆì—­','ê³µìœ ','ì‹ ê³ ','ì ‘ê¸°','ë”ë³´ê¸°','ì§€ë„ë³´ê¸°','ê¸¸ì°¾ê¸°','ì „í™”',
    'ì¢‹ì•„ìš”','ëŒ“ê¸€','ë©”ë‰´','ì‚¬ì¥ë‹˜','ì‚¬ì¥ë‹˜ ëŒ“ê¸€','ë‹µê¸€','ê´€ì‹¬',
  ];
  const isSymbolOnly = (s: string) => s.length <= 3 && /^[^\wê°€-í£]+$/.test(s);
  const filtered = rawLines.filter(l => l && !uiWords.some(w => l === w || l.includes(w)) && !isSymbolOnly(l));
  // ìƒë‹¨ ê³ ì • í—¤ë” ì˜ì—­ ì»·(í…ìŠ¤íŠ¸ ìƒë‹¨ 10% ê°€ì •)
  // í…ìŠ¤íŠ¸ ê¸°ë°˜ ì»·ì´ë¯€ë¡œ ì²« 2~3ì¤„ì— ë…¸ì´ì¦ˆê°€ ëª°ë¦´ ë•Œ ì œê±°
  const startIdx = Math.min(3, Math.floor(filtered.length * 0.1));
  return filtered.slice(startIdx).join('\n').trim();
}

function parseNaver(text: string): { author: string; body: string; date: string; business: string } {
  const rawLines = text.split('\n').map(l => l.trim());
  const lines = rawLines.filter(Boolean);
  let author = '';
  let date = '';
  let business = '';

  // í›„ë³´: ì²« ì¤„(ë§ˆìŠ¤í‚¹ ì´ë¦„), í˜¹ì€ "ì‘ì„±ì: xxx"
  const top = lines[0] || '';
  if (/^[A-Za-z0-9ê°€-í£*]{2,15}$/.test(top)) author = top;
  const authorLine = lines.find(l => /ì‘ì„±ì\s*[:ï¼š]/.test(l));
  if (authorLine) {
    const m = authorLine.match(/[:ï¼š]\s*(.+)$/);
    if (m) author = m[1].trim();
  }

  // ë¦¬ë·°/ì‚¬ì§„/íŒ”ë¡œìš° ë“± ìƒë‹¨ ë©”íƒ€ ì œê±° + ìƒë‹¨ ë„¤ë¹„/ì‹œê³„/ì‹¬ë³¼ ë…¸ì´ì¦ˆ ì œê±°
  const noiseTop = [
    /^ë¦¬ë·°\s*\d+(?:ê°œ)?$/,
    /^ì‚¬ì§„\s*\d+(?:ì¥)?$/,
    /^íŒ”ë¡œìš°(?:\s*\+?\d+)?$/i,
    /^íŒ”ë¡œì‰$/,
    /^í”„ë¡œí•„$/,
    /^í›„ê¸°\s*ëª¨ì•„ë³´ê¸°$/,
    /^(í™ˆ\s*)(ì†Œì‹)?\s*(ì˜ˆì•½)?\s*(ë¦¬ë·°)?$/,
    /^ì£¼ë³€$/,
    /^ì •ë³´$/,
    /^ì§€ë„ë³´ê¸°?$/,
    /^ê¸¸ì°¾ê¸°$/,
    /^ì „í™”$/,
    /^ì €ì¥$/
  ];
  let start = 0;
  const isSymbolOnly = (s: string) => /^[^\wê°€-í£]+$/.test(s);
  const looksLikeClock = (s: string) => /\d{1,2}:\d{2}/.test(s);
  const looksLikeNetwork = (s: string) => /(5G|LTE|wifi|Wi-?Fi|X)/i.test(s);

  for (let i = 0; i < lines.length; i++) {
    const l = lines[i];
    if (i === 0 && author && l === author) { start = i + 1; continue; }
    if (noiseTop.some(r => r.test(l))) { start = i + 1; continue; }
    if (/^\[[^\]]+\]$/.test(l)) { start = i + 1; continue; } // ì¹´í…Œê³ ë¦¬ íƒœê·¸ [ë³´ì»¬, ë¯¸ë””]
    if (/^ë¦¬ë·°\s*[\d,]+\s*[.,Â·]\s*ì‚¬ì§„\s*[\d,]+$/.test(l)) { start = i + 1; continue; }
    // ì—°ì†ì ìœ¼ë¡œ ë©”íƒ€ë§Œ ìˆëŠ” êµ¬ê°„ ìŠ¤í‚µ
    if (i <= 6 && (l.length <= 3 || /^(íŒ”ë¡œìš°|íŒ”ë¡œì‰)$/.test(l) || isSymbolOnly(l) || looksLikeClock(l) || looksLikeNetwork(l))) { start = i + 1; continue; }
    break;
  }

  // í•˜ë‹¨ ë…¸ì´ì¦ˆ(ì ‘ê¸°/ì‹œì„¤ íƒœê·¸ë¥˜) ì»·ì˜¤í”„
  const bottomNoise = [
    'ì ‘ê¸°', 'ë”ë³´ê¸°', 'ë²ˆì—­', 'ê³µìœ ', 'ì‹ ê³ ', 'ë©”ë‰´', 'ë‹µê¸€', 'ì‚¬ì¥ë‹˜', 'ì‚¬ì¥ë‹˜ ëŒ“ê¸€',
    'ì‹œì„¤ì´ ê¹”ë”í•´ìš”', 'ì•„ëŠ‘í•´ìš”', 'ì‹¤ë ¥ì´', 'ì¹œì ˆí•´ìš”', 'ì¬ë°©ë¬¸', 'ì¶”ì²œ', 'ê°€ì„±ë¹„ê°€ ì¢‹ì•„ìš”',
  ];
  let end = lines.length;
  for (let i = start; i < lines.length; i++) {
    if (lines[i] === 'ì ‘ê¸°') { end = i; break; }
    if (bottomNoise.some(k => lines[i].includes(k)) && (i - start) > 1) { end = i; break; }
  }

  // ë³¸ë¬¸ í›„ë³´
  let bodyLines = lines.slice(start, end);
  // ì¤‘ê°„ì— ë¼ì–´ë“  í•˜íŠ¸/ë¶ˆë¦¿/ë‹¨ì–´ íƒœê·¸ ì •ë¦¬
  bodyLines = bodyLines.filter(l => !/^[â€¢â™¡â™¥â€»â–¶Â·ã†]+/.test(l));
  // ì§§ì€ íƒœê·¸ì„± ë¼ì¸ ì œê±°(2~4ê¸€ì, â€˜í•´ìš”/ì¢‹ì•„ìš”/ê¹”ë”/ì•„ëŠ‘â€™ ë“± í‚¤ì›Œë“œ í¬í•¨)
  const tagHints = ['í•´ìš”', 'ì¢‹ì•„ìš”', 'ê¹”ë”', 'ì•„ëŠ‘', 'ì¬ë°©ë¬¸', 'ì¶”ì²œ', 'ì¹œì ˆ', 'ì‹¤ë ¥', 'ê°€ì„±ë¹„'];
  bodyLines = bodyLines.filter(l => !(l.length <= 6 && tagHints.some(k => l.includes(k))));
  // ë‚ ì§œ í›„ë³´ë¥¼ ë³¸ë¬¸ ìƒí•˜ë‹¨ì—ì„œ íƒìƒ‰
  const dateLine = bodyLines.find(l => /(\d{4}[.\-]\d{1,2}[.\-]\d{1,2})|(\d{1,2}[.\-]\d{1,2})|(\d+\s*ì¼\s*ì „)|(ì–´ì œ|ê·¸ì œ)/.test(l))
    || rawLines.reverse().find(l => /(\d{4}|\d{2})[.\-]\d{1,2}[.\-]\d{1,2}/.test(l));
  if (dateLine) {
    const d = analyzeReviewText(dateLine).date; // reuse
    if (d) date = d;
    // ë‚ ì§œë§Œ ìˆëŠ” ë¼ì¸ì€ ë³¸ë¬¸ì—ì„œ ì œê±°
    bodyLines = bodyLines.filter(l => l !== dateLine);
  }

  // ì”ì—¬ ë…¸ì´ì¦ˆ ë¼ì¸ í•„í„°
  bodyLines = bodyLines.filter(l => !/^ë¦¬ë·°\s*\d+|^ì‚¬ì§„\s*\d+|^íŒ”ë¡œìš°/.test(l));
  // ì¶”ê°€ ë…¸ì´ì¦ˆ: ë‹¨ì¼ ê¸°í˜¸/ë³„/ë¬¼ìŒí‘œ/ë‹¨ë… X ë¼ì¸ ì‚­ì œ
  bodyLines = bodyLines.filter(l => !/^(\?|x|X|â˜†|â˜…|\*|\-|=|â€”|Â·|ã†)$/.test(l));

  // ë¹„ì¦ˆë‹ˆìŠ¤ëª… í›„ë³´: ìƒë‹¨ ê·¼ì²˜ì˜ í•œêµ­ì–´ ì¤‘ì‹¬ ë¼ì¸ ì¤‘ ë…¸ì´ì¦ˆ ì œì™¸, íŠ¹ì • í‚¤ì›Œë“œ í¬í•¨ ìš°ì„ 
  const bizKeywords = ['í•™ì›','í´ë˜ìŠ¤','ìŠ¤íŠœë””ì˜¤','ì„¼í„°','ìƒµ','ë®¤ì§','í•„ë¼í…ŒìŠ¤','PT','ë·°í‹°','í—¤ì–´','ë„¤ì¼','ìš”ê°€','ë³´ì»¬'];
  const isNoise = (s: string) => /^(í™ˆ|ë¦¬ë·°|ì‚¬ì§„|ì •ë³´|ì§€ë„|ê¸¸ì°¾ê¸°|ì „í™”|ì €ì¥|ê³µìœ |ë¦¬ë·°\s|ì‚¬ì§„\s|íŒ”ë¡œìš°|íŒ”ë¡œì‰|í”„ë¡œí•„|í›„ê¸°\s*ëª¨ì•„ë³´ê¸°)$/.test(s);
  const topWindow = lines.slice(0, Math.min(lines.length, 12));
  const bizCandidates = topWindow
    .filter(l => !isNoise(l) && /[ê°€-í£]{2,}/.test(l) && l.length <= 30)
    .map(l => ({ l, score: bizKeywords.some(k => l.includes(k)) ? 2 : 1 }))
    .sort((a,b)=> b.score - a.score || b.l.length - a.l.length);
  if (bizCandidates[0]) business = bizCandidates[0].l.replace(/[â€ â€¡â˜…â˜†âœ©âœ­âœ®âœ¯â­ï¸]+/g,'').trim();

  const body = bodyLines.join('\n').trim();
  return { author, body, date, business };
}

// Kakao style: ìƒë‹¨ ë‹‰ë„¤ì„/ë³„ì /ë°©ë¬¸ì¼ì, í•˜ë‹¨ "ì§€ë„ë³´ê¸°/ê³µìœ /ì‹ ê³ " ë˜ëŠ” "ì¢‹ì•„ìš”"ë¥˜ ì œê±°
function parseKakao(text: string): { author: string; body: string; date: string } {
  const lines = text.split('\n').map(l => l.trim()).filter(Boolean);
  let author = '';
  let date = '';

  // ì²« ì¤„ ë‹‰ë„¤ì„ ë˜ëŠ” "ì‘ì„±ì:"
  const top = lines[0] || '';
  if (/^[A-Za-z0-9ê°€-í£*]{2,15}$/.test(top)) author = top;
  const authorLine = lines.find(l => /ì‘ì„±ì\s*[:ï¼š]/.test(l));
  if (authorLine) author = authorLine.split(/[:ï¼š]/)[1]?.trim() || author;

  // ìƒë‹¨ ë©”íƒ€/ë²„íŠ¼ ì œê±°
  const topNoise = [/^ì§€ë„ë³´ê¸°$/, /^ê³µìœ $/, /^ì‹ ê³ $/, /^ì¢‹ì•„ìš”\s*\d*$/, /^íŒ”ë¡œìš°$/];
  let start = 0;
  for (let i = 0; i < lines.length; i++) {
    if (i <= 2 && (lines[i] === author || topNoise.some(r => r.test(lines[i])))) {
      start = i + 1; continue;
    }
    break;
  }

  // í•˜ë‹¨ ë…¸ì´ì¦ˆ ì œê±°
  const bottomNoise = ['ë”ë³´ê¸°', 'ì ‘ê¸°', 'ê³µìœ ', 'ì‹ ê³ ', 'ë²ˆì—­', 'ì¢‹ì•„ìš”'];
  let end = lines.length;
  for (let i = start; i < lines.length; i++) {
    if (bottomNoise.some(k => lines[i].includes(k)) && (i - start) > 1) { end = i; break; }
  }

  let bodyLines = lines.slice(start, end);
  // ë°©ë¬¸ì¼/ì‘ì„±ì¼ ì¶”ì¶œ
  const dateLine = bodyLines.find(l => /(\d{4}[.\-]\d{1,2}[.\-]\d{1,2})|(\d{1,2}[.\-]\d{1,2})|(\d+\s*ì¼\s*ì „)|(ì–´ì œ|ê·¸ì œ)/.test(l));
  if (dateLine) {
    const d = analyzeReviewText(dateLine).date;
    if (d) date = d;
    bodyLines = bodyLines.filter(l => l !== dateLine);
  }

  // íƒœê·¸/ì†ì„± ë¼ì¸ ì œê±°(ì˜ˆ: ë¶„ìœ„ê¸°/ì„œë¹„ìŠ¤/ê°€ê²©ëŒ€ ë“±)
  const attrHints = ['ë¶„ìœ„ê¸°', 'ì„œë¹„ìŠ¤', 'ê°€ê²©', 'ë©”ë‰´', 'ì²­ê²°', 'ì§ì›', 'ì¶”ì²œ'];
  bodyLines = bodyLines.filter(l => !attrHints.some(k => l.includes(k)));

  return { author, body: bodyLines.join('\n').trim(), date };
}

// Generic cleanup for platforms: drop common UI words
function parseGeneric(text: string): string {
  const lines = text.split('\n').map(l => l.trim()).filter(Boolean);
  const ui = ['ì ‘ê¸°', 'ë”ë³´ê¸°', 'ê³µìœ ', 'ì‹ ê³ ', 'ë²ˆì—­', 'íŒ”ë¡œìš°', 'í”„ë¡œí•„'];
  return lines.filter(l => !ui.includes(l)).join('\n').trim();
}

// Heuristic re-ordering using geometry (blocks/paragraphs/words)
function rebuildReadingOrder(result: any): string | null {
  // Prefer paragraph-level reconstruction from fullTextAnnotation
  const pages = result.fullTextAnnotation?.pages || [];
  const lines: { x: number; y: number; text: string }[] = [];

  const getCenter = (vertices: any[]) => {
    const xs = vertices.map((v: any) => v.x || 0);
    const ys = vertices.map((v: any) => v.y || 0);
    const x = (Math.min(...xs) + Math.max(...xs)) / 2;
    const y = (Math.min(...ys) + Math.max(...ys)) / 2;
    const h = Math.max(...ys) - Math.min(...ys);
    return { x, y, h };
  };

  // Estimate page height for y-based trimming
  let pageMaxY = 0;
  for (const page of pages) {
    for (const block of page.blocks || []) {
      for (const para of block.paragraphs || []) {
        const words = (para.words || []).map((w: any) => (w.symbols || []).map((s: any) => s.text).join(''));
        const text = words.join(' ').trim();
        if (!text) continue;
        const { x, y } = getCenter(para.boundingBox?.vertices || []);
        pageMaxY = Math.max(pageMaxY, ...(para.boundingBox?.vertices || []).map((v: any) => v.y || 0));
        lines.push({ x, y, text });
      }
    }
  }

  // Fallback to word annotations if no paragraphs
  if (lines.length === 0 && Array.isArray(result.textAnnotations)) {
    const words = result.textAnnotations.slice(1).map((a: any) => {
      const { x, y, h } = getCenter(a.boundingPoly?.vertices || []);
      return { x, y, h, text: a.description };
    });
    if (words.length === 0) return null;
    // Group words into lines by similar Y (tolerance relative to word height)
    words.sort((a: any, b: any) => (a.y === b.y ? a.x - b.x : a.y - b.y));
    const grouped: { y: number; items: typeof words }[] = [];
    for (const w of words) {
      const band = grouped.find(g => Math.abs(g.y - w.y) <= Math.max(8, w.h * 0.6));
      if (band) {
        band.items.push(w);
        // keep representative y as average for stability
        band.y = (band.y * (band.items.length - 1) + w.y) / band.items.length;
      } else {
        grouped.push({ y: w.y, items: [w] });
      }
    }
    // Sort bands top->bottom, words left->right
    grouped.sort((a, b) => a.y - b.y);
    const rebuiltText = grouped
      .map(g => g.items.sort((a, b) => a.x - b.x).map(i => i.text).join(' '))
      .join('\n');
    return rebuiltText.trim();
  }

  // Simple multi-column handling: split by big x gaps if needed could be added later
  // Optional: cut fixed header region (top 12% by default)
  const cutRatio = Number(process.env.OCR_TOP_CUT_RATIO || 0.12);
  const yCut = pageMaxY ? pageMaxY * cutRatio : 0;
  const filtered = yCut ? lines.filter(l => l.y >= yCut) : lines;

  // Sort paragraph lines by y then x
  filtered.sort((a, b) => (a.y === b.y ? a.x - b.x : a.y - b.y));
  return filtered.map(l => l.text).join('\n').trim() || null;
}

// Post-OCR spacing refinement for Korean-heavy lines
function refineSpacing(text: string): string {
  return text.split('\n').map(line => {
    const tokens = line.trim().split(/\s+/);
    const hangul = /[\uAC00-\uD7AF]/;
    const singleHangul = tokens.filter(t => t.length === 1 && hangul.test(t)).length;
    const ratio = tokens.length ? singleHangul / tokens.length : 0;
    if (ratio >= 0.5) {
      // Collapse spaces between Hangul letters, keep punctuation spacing sane
      return line
        .replace(/(?<=[\uAC00-\uD7AF])\s+(?=[\uAC00-\uD7AF])/g, '')
        .replace(/\s+([,\.\!\?%\)\]\}])/g, '$1')
        .replace(/([\(\[\{])\s+/g, '$1');
    }
    return line;
  }).join('\n');
}

async function normalizeForAnalysis(raw: string) {
  const refined = refineSpacing(raw);
  const denoised = stripNoiseLocal(refined);
  const spaced = await improveSpacingViaService(denoised);
  const baseText = spaced ?? denoised;
  return {
    refined,
    denoised,
    baseText,
    spacingApplied: Boolean(spaced)
  };
}
